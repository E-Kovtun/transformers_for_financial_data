{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download ru_core_news_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install performer_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from performer_pytorch import PerformerLM\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "import utils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3751083, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = utils.read_preprocessed_financial_data(data_folder, enc_cols=['mcc_description', 'tr_description'])\n",
    "df.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>tr_datetime</th>\n",
       "      <th>mcc_code</th>\n",
       "      <th>tr_type</th>\n",
       "      <th>amount</th>\n",
       "      <th>term_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>mcc_description</th>\n",
       "      <th>tr_description</th>\n",
       "      <th>week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39026145.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4814.0</td>\n",
       "      <td>1030</td>\n",
       "      <td>-2245.92</td>\n",
       "      <td>311690</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[-0.102810316, -0.12563597, -0.11075681, -0.06...</td>\n",
       "      <td>[0.07799721, 0.21862344, 0.1882922, -0.1851609...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39026145.0</td>\n",
       "      <td>13328582400</td>\n",
       "      <td>4814.0</td>\n",
       "      <td>1030</td>\n",
       "      <td>-5614.79</td>\n",
       "      <td>311690</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[-0.102810316, -0.12563597, -0.11075681, -0.06...</td>\n",
       "      <td>[0.07799721, 0.21862344, 0.1882922, -0.1851609...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39026145.0</td>\n",
       "      <td>17673984000</td>\n",
       "      <td>4814.0</td>\n",
       "      <td>1030</td>\n",
       "      <td>-1122.96</td>\n",
       "      <td>311690</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[-0.102810316, -0.12563597, -0.11075681, -0.06...</td>\n",
       "      <td>[0.07799721, 0.21862344, 0.1882922, -0.1851609...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39026145.0</td>\n",
       "      <td>30168547200</td>\n",
       "      <td>4814.0</td>\n",
       "      <td>1030</td>\n",
       "      <td>-2245.92</td>\n",
       "      <td>311690</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[-0.102810316, -0.12563597, -0.11075681, -0.06...</td>\n",
       "      <td>[0.07799721, 0.21862344, 0.1882922, -0.1851609...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39026145.0</td>\n",
       "      <td>48592051200</td>\n",
       "      <td>4814.0</td>\n",
       "      <td>1030</td>\n",
       "      <td>-2245.92</td>\n",
       "      <td>311690</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[-0.102810316, -0.12563597, -0.11075681, -0.06...</td>\n",
       "      <td>[0.07799721, 0.21862344, 0.1882922, -0.1851609...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  tr_datetime  mcc_code  tr_type   amount  term_id  gender  \\\n",
       "0   39026145.0            0    4814.0     1030 -2245.92   311690     1.0   \n",
       "1   39026145.0  13328582400    4814.0     1030 -5614.79   311690     1.0   \n",
       "2   39026145.0  17673984000    4814.0     1030 -1122.96   311690     1.0   \n",
       "3   39026145.0  30168547200    4814.0     1030 -2245.92   311690     1.0   \n",
       "4   39026145.0  48592051200    4814.0     1030 -2245.92   311690     1.0   \n",
       "\n",
       "                                     mcc_description  \\\n",
       "0  [-0.102810316, -0.12563597, -0.11075681, -0.06...   \n",
       "1  [-0.102810316, -0.12563597, -0.11075681, -0.06...   \n",
       "2  [-0.102810316, -0.12563597, -0.11075681, -0.06...   \n",
       "3  [-0.102810316, -0.12563597, -0.11075681, -0.06...   \n",
       "4  [-0.102810316, -0.12563597, -0.11075681, -0.06...   \n",
       "\n",
       "                                      tr_description  week  \n",
       "0  [0.07799721, 0.21862344, 0.1882922, -0.1851609...     0  \n",
       "1  [0.07799721, 0.21862344, 0.1882922, -0.1851609...     0  \n",
       "2  [0.07799721, 0.21862344, 0.1882922, -0.1851609...     1  \n",
       "3  [0.07799721, 0.21862344, 0.1882922, -0.1851609...     1  \n",
       "4  [0.07799721, 0.21862344, 0.1882922, -0.1851609...     1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:06<00:00, 15.09it/s]\n"
     ]
    }
   ],
   "source": [
    "clients = df['customer_id'].unique()\n",
    "clients = clients[:100] # drop this row (I just tested the code with small amount of data)\n",
    "\n",
    "df_week = []\n",
    "\n",
    "for client_id in tqdm(clients):\n",
    "    client_data = df[df['customer_id'] == client_id]\n",
    "    client_weeks = client_data.week.unique()\n",
    "    \n",
    "    for week in client_weeks:\n",
    "        client_data_week = client_data[client_data['week'] == week]\n",
    "        df_week.append(\n",
    "            {\n",
    "                'transactions': client_data_week['mcc_code'].tolist(),\n",
    "                'amounts': client_data_week['amount'].tolist(),\n",
    "                'tr_datetime': client_data_week['tr_datetime'].tolist(),\n",
    "                'tr_type': client_data_week['tr_type'].tolist(),\n",
    "                'mcc_description': client_data_week['mcc_description'].tolist(), # add mcc_description embeddings\n",
    "                'tr_description': client_data_week['tr_description'].tolist(), # add tr_description embeddings\n",
    "                'term_id': client_data_week['term_id'].tolist(),\n",
    "                'customer_id': client_id, \n",
    "                'week': week,\n",
    "                'gender': client_data_week['gender'].tolist()\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5990, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_week = pd.DataFrame(df_week)\n",
    "df_week.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transactions</th>\n",
       "      <th>amounts</th>\n",
       "      <th>tr_datetime</th>\n",
       "      <th>tr_type</th>\n",
       "      <th>mcc_description</th>\n",
       "      <th>tr_description</th>\n",
       "      <th>term_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>week</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[4814.0, 4814.0, 5499.0, 5499.0, 5499.0, 5499....</td>\n",
       "      <td>[-2245.92, -5614.79, -1392.47, -920.83, -1010....</td>\n",
       "      <td>[0, 13328582400, 3317241600, 9680601600, 14449...</td>\n",
       "      <td>[1030, 1030, 1010, 1010, 1010, 1010, 1010, 101...</td>\n",
       "      <td>[[-0.102810316, -0.12563597, -0.11075681, -0.0...</td>\n",
       "      <td>[[0.07799721, 0.21862344, 0.1882922, -0.185160...</td>\n",
       "      <td>[311690, 311690, 311690, 311690, 311690, 31169...</td>\n",
       "      <td>39026145.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[4814.0, 4814.0, 4814.0, 4814.0, 4814.0, 5499....</td>\n",
       "      <td>[-1122.96, -2245.92, -2245.92, -2245.92, -2245...</td>\n",
       "      <td>[17673984000, 30168547200, 48592051200, 487840...</td>\n",
       "      <td>[1030, 1030, 1030, 1030, 1030, 1010, 1010, 101...</td>\n",
       "      <td>[[-0.102810316, -0.12563597, -0.11075681, -0.0...</td>\n",
       "      <td>[[0.07799721, 0.21862344, 0.1882922, -0.185160...</td>\n",
       "      <td>[311690, 311690, 311690, 311690, 311690, 31169...</td>\n",
       "      <td>39026145.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[4814.0, 4814.0, 4814.0, 5331.0, 5331.0, 5331....</td>\n",
       "      <td>[-2245.92, -449.18, -1122.96, -6288.56, -1122....</td>\n",
       "      <td>[42837984000, 79248240000, 79340169600, 0, 0, ...</td>\n",
       "      <td>[1030, 1030, 1030, 1110, 1110, 1110, 1110, 101...</td>\n",
       "      <td>[[-0.102810316, -0.12563597, -0.11075681, -0.0...</td>\n",
       "      <td>[[0.07799721, 0.21862344, 0.1882922, -0.185160...</td>\n",
       "      <td>[311690, 311690, 311690, 311690, 311690, 31169...</td>\n",
       "      <td>39026145.0</td>\n",
       "      <td>2</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        transactions  \\\n",
       "0  [4814.0, 4814.0, 5499.0, 5499.0, 5499.0, 5499....   \n",
       "1  [4814.0, 4814.0, 4814.0, 4814.0, 4814.0, 5499....   \n",
       "2  [4814.0, 4814.0, 4814.0, 5331.0, 5331.0, 5331....   \n",
       "\n",
       "                                             amounts  \\\n",
       "0  [-2245.92, -5614.79, -1392.47, -920.83, -1010....   \n",
       "1  [-1122.96, -2245.92, -2245.92, -2245.92, -2245...   \n",
       "2  [-2245.92, -449.18, -1122.96, -6288.56, -1122....   \n",
       "\n",
       "                                         tr_datetime  \\\n",
       "0  [0, 13328582400, 3317241600, 9680601600, 14449...   \n",
       "1  [17673984000, 30168547200, 48592051200, 487840...   \n",
       "2  [42837984000, 79248240000, 79340169600, 0, 0, ...   \n",
       "\n",
       "                                             tr_type  \\\n",
       "0  [1030, 1030, 1010, 1010, 1010, 1010, 1010, 101...   \n",
       "1  [1030, 1030, 1030, 1030, 1030, 1010, 1010, 101...   \n",
       "2  [1030, 1030, 1030, 1110, 1110, 1110, 1110, 101...   \n",
       "\n",
       "                                     mcc_description  \\\n",
       "0  [[-0.102810316, -0.12563597, -0.11075681, -0.0...   \n",
       "1  [[-0.102810316, -0.12563597, -0.11075681, -0.0...   \n",
       "2  [[-0.102810316, -0.12563597, -0.11075681, -0.0...   \n",
       "\n",
       "                                      tr_description  \\\n",
       "0  [[0.07799721, 0.21862344, 0.1882922, -0.185160...   \n",
       "1  [[0.07799721, 0.21862344, 0.1882922, -0.185160...   \n",
       "2  [[0.07799721, 0.21862344, 0.1882922, -0.185160...   \n",
       "\n",
       "                                             term_id  customer_id  week  \\\n",
       "0  [311690, 311690, 311690, 311690, 311690, 31169...   39026145.0     0   \n",
       "1  [311690, 311690, 311690, 311690, 311690, 31169...   39026145.0     1   \n",
       "2  [311690, 311690, 311690, 311690, 311690, 31169...   39026145.0     2   \n",
       "\n",
       "                                              gender  \n",
       "0  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...  \n",
       "1  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...  \n",
       "2  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_week.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(598, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MIN_LEN = 20\n",
    "MAX_LEN = 50\n",
    "\n",
    "lens = df_week.transactions.apply(lambda x: len(x))\n",
    "df_week = df_week[(lens >= MIN_LEN) & (lens <= MAX_LEN)]\n",
    "df_week.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['transactions', 'amounts', 'tr_datetime', 'tr_type', 'term_id'] #, 'mcc_description'] #, 'tr_description'] \n",
    "desc_cols = ['mcc_description', 'tr_description']\n",
    "\n",
    "INPUT_SIZE = len(list(set(features) - set(desc_cols)))\n",
    "if 'mcc_description' in features:\n",
    "    INPUT_SIZE += len(df['mcc_description'].iloc[0])\n",
    "if 'tr_description' in features:\n",
    "    INPUT_SIZE += len(df['tr_description'].iloc[0])\n",
    "    \n",
    "EPOCHS = 10\n",
    "N_SPLITS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ClassificationModel(pl.LightningModule):\n",
    "#     def __init__(self, model, train_data, test_data, batch_size=64, learning_rate=1e-3):\n",
    "#         super(ClassificationModel, self).__init__()\n",
    "#         self.model = model\n",
    "\n",
    "#         self.batch_size = batch_size\n",
    "#         self.loss_function = nn.BCELoss()\n",
    "\n",
    "#         self.train_data = train_data\n",
    "#         self.val_data = test_data\n",
    "\n",
    "#         self.learning_rate = learning_rate\n",
    "\n",
    "#     def forward(self, inputs):\n",
    "#         print('in forward')\n",
    "#         print('without resize')\n",
    "#         try:\n",
    "#             a = self.model(inputs)\n",
    "#             print(a)\n",
    "#         except:\n",
    "#             print('a = self.model(inputs) does not work')\n",
    "#             try:\n",
    "#                 a = self.model(inputs.float())\n",
    "#                 print(a)\n",
    "#             except:\n",
    "#                 print('a = self.model(inputs.float()) does not work')\n",
    "#                 try:\n",
    "#                     a = self.model(inputs.long())\n",
    "#                     print(a)\n",
    "#                 except:\n",
    "#                     print('a = self.model(inputs.long()) does not work')\n",
    "#                     print('\\n\\ntry with resize')\n",
    "#                     inputs = inputs.resize(inputs.size()[0]*inputs.size()[1], inputs.size()[-1])\n",
    "#                     print('new inputs size', inputs.size())\n",
    "#                     try:\n",
    "#                         a = self.model(inputs)\n",
    "#                         print(a)\n",
    "#                     except:\n",
    "#                         print('a = self.model(inputs) does not work')\n",
    "#                         try:\n",
    "#                             a = self.model(inputs.float())\n",
    "#                             print(a)\n",
    "#                         except:\n",
    "#                             print('a = self.model(inputs.float()) does not work')\n",
    "#                             try:\n",
    "#                                 a = self.model(inputs.long())\n",
    "#                                 print(a)\n",
    "#                             except:\n",
    "#                                 print('a = self.model(inputs.long()) does not work')\n",
    "#         inputs = inputs.resize(inputs.size()[0]*inputs.size()[1], inputs.size()[-1])\n",
    "#         return self.model(inputs)\n",
    "\n",
    "#     @staticmethod\n",
    "#     def calculate_metrics(target, y_pred):\n",
    "#         target = target.detach().cpu().numpy()\n",
    "#         y_pred = y_pred.detach().cpu().numpy()\n",
    "#         acc = accuracy_score(target, y_pred > 0.5)\n",
    "\n",
    "#         try:\n",
    "#             roc_auc = roc_auc_score(target, y_pred)\n",
    "#         except ValueError:\n",
    "#             roc_auc = acc\n",
    "#         pr_auc = average_precision_score(target, y_pred)\n",
    "\n",
    "#         return acc, roc_auc, pr_auc\n",
    "\n",
    "#     def training_step(self, batch, batch_idx):\n",
    "#         print('in training step')\n",
    "#         sample, target = batch\n",
    "#         print(sample, '\\n------------------------------------------------------------------\\n', target)\n",
    "#         pred = self.forward(sample.long())\n",
    "#         print('pred\\n', pred)\n",
    "\n",
    "#         train_loss = self.loss_function(pred.squeeze(), target.float())\n",
    "#         train_accuracy = (target == (pred.squeeze() > 0.5)).float().mean()\n",
    "\n",
    "#         self.log(\"train_loss\", train_loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "#         self.log(\n",
    "#             \"train_acc\", train_accuracy, on_step=False, on_epoch=True, prog_bar=True\n",
    "#         )\n",
    "\n",
    "#         return train_loss\n",
    "\n",
    "#     def validation_step(self, batch, batch_idx):\n",
    "#         print('in validation step')\n",
    "#         sample, target = batch\n",
    "#         print(sample, '\\n------------------------------------------------------------------\\n', target)\n",
    "#         #pred = self.forward(sample.long())\n",
    "#         pred = self.forward(sample)\n",
    "\n",
    "#         val_loss = self.loss_function(pred.squeeze(), target.float())\n",
    "#         val_accuracy = (target == (pred.squeeze() > 0.5)).float().mean()\n",
    "\n",
    "#         self.log(\"val_loss\", val_loss, prog_bar=True)\n",
    "#         self.log(\"val_acc\", val_accuracy, prog_bar=True)\n",
    "\n",
    "#         return {\n",
    "#             \"val_loss\": val_loss,\n",
    "#             \"val_acc\": val_accuracy,\n",
    "#             \"val_target\": target,\n",
    "#             \"val_predictions\": pred,\n",
    "#         }\n",
    "\n",
    "#     def validation_epoch_end(self, outputs):\n",
    "#         predictions = torch.cat([x[\"val_predictions\"] for x in outputs])\n",
    "#         target = torch.cat([x[\"val_target\"] for x in outputs])\n",
    "\n",
    "#         accuracy, roc_auc, pr_auc = self.calculate_metrics(\n",
    "#             target.squeeze(), predictions.squeeze()\n",
    "#         )\n",
    "\n",
    "#         log_dict = {\n",
    "#             \"mean_accuracy\": accuracy,\n",
    "#             \"mean_roc_auc\": roc_auc,\n",
    "#             \"mean_pr_auc\": pr_auc,\n",
    "#         }\n",
    "\n",
    "#         for k, v in log_dict.items():\n",
    "#             self.log(k, v, prog_bar=True)\n",
    "\n",
    "#     def configure_optimizers(self):\n",
    "#         opt = torch.optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "#         return opt\n",
    "\n",
    "#     def train_dataloader(self):\n",
    "#         train_dataloader = torch.utils.data.DataLoader(\n",
    "#             self.train_data, batch_size=self.batch_size, shuffle=True, num_workers=4\n",
    "#         )\n",
    "#         return train_dataloader\n",
    "\n",
    "#     def val_dataloader(self):\n",
    "#         val_dataloader = torch.utils.data.DataLoader(\n",
    "#             self.val_data, batch_size=self.batch_size, shuffle=False, num_workers=4\n",
    "#         )\n",
    "#         return val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model = PerformerLM(\n",
    "#     num_tokens = INPUT_SIZE,\n",
    "#     max_seq_len = 2048,\n",
    "#     dim = 1,\n",
    "#     heads = 1, \n",
    "#     depth = 1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, loss_function): \n",
    "    predictions = []\n",
    "    probas = []\n",
    "    targets = []\n",
    "    val_loss = 0\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for data, target in test_loader:\n",
    "            prediction = model(data)\n",
    "            loss = loss_function(prediction, target.long())\n",
    "            \n",
    "            probas += np.exp(np.array(prediction))[:, 1].tolist()\n",
    "            val_loss += np.array(loss)\n",
    "            \n",
    "            _, prediction = torch.max(prediction, dim=1) \n",
    "        \n",
    "            predictions += np.array(prediction).tolist()\n",
    "            targets += target.long().detach().numpy().tolist()\n",
    "\n",
    "    acc = accuracy_score(targets, predictions)\n",
    "    roc_auc = roc_auc_score(targets, probas)\n",
    "    pr_auc = average_precision_score(targets, probas)\n",
    "\n",
    "    return predictions, probas, targets, val_loss/len(test_loader), acc, roc_auc, pr_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fit(model, EPOCHS, loss_function, train_loader, val_loader, n):\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "    for epoch in range(EPOCHS):\n",
    "        train_epoch_loss = 0\n",
    "        train_epoch_acc = 0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "#             batch_size = data.size(0)\n",
    "        \n",
    "#             model.hidden_cell = (torch.zeros(1, n, 20),\n",
    "#                                  torch.zeros(1, n, 20))\n",
    "\n",
    "            print('data.size()', data.size())\n",
    "            data = data.resize(data.size()[0]*data.size()[1], data.size()[-1])\n",
    "            y_pred = model(data.long())\n",
    "            loss = loss_function(y_pred, target.long())\n",
    "            acc = multi_acc(y_pred, target)\n",
    "            train_epoch_loss += loss.item()\n",
    "            train_epoch_acc += acc.data.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()   \n",
    "\n",
    "        _, _, _, val_loss, val_acc, _, _ = test_model(model, val_loader, loss_function)\n",
    "\n",
    "        print('Epoch {}: train accuracy={}, train loss={}, val accuracy={}, val loss={}'.format(epoch+1, \n",
    "                                                                                                train_epoch_acc/(batch_idx+1), \n",
    "                                                                                                train_epoch_loss/(batch_idx+1),\n",
    "                                                                                                val_acc,\n",
    "                                                                                                val_loss))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.size() torch.Size([32, 321, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:493: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-7daff95089dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m     )\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mINPUT_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroc_auc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpr_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroc_auc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpr_auc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-67e81a40cbfc>\u001b[0m in \u001b[0;36mmodel_fit\u001b[0;34m(model, EPOCHS, loss_function, train_loader, val_loader, n)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data.size()'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/performer_pytorch/performer_pytorch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, return_encodings, **kwargs)\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m         \u001b[0;31m# token and positional embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    653\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    158\u001b[0m         return F.embedding(\n\u001b[1;32m    159\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2042\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2043\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2044\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "loss_function = nn.BCELoss()\n",
    "group_kfold = GroupKFold(n_splits=N_SPLITS)\n",
    "metrics = {'Accuracy': [], 'ROC AUC': [], 'PR AUC': []}\n",
    "for i, (train_index, test_index) in enumerate(group_kfold.split(X=df_week, groups=df_week['customer_id'])):\n",
    "    train_data = df_week.iloc[train_index]\n",
    "    test_data = df_week.iloc[test_index]\n",
    "\n",
    "    random.seed(123)\n",
    "    val_customer_id = random.sample(train_data['customer_id'].unique().tolist(), int(train_data['customer_id'].nunique() * 0.3))\n",
    "    val_data = train_data[train_data['customer_id'].isin(val_customer_id)]\n",
    "    train_data = train_data[~train_data['customer_id'].isin(val_customer_id)]\n",
    "\n",
    "    train_dataset = utils.create_dataset(train_data, features, batch_size=64, shuffle=True)\n",
    "    val_dataset = utils.create_dataset(val_data, features, batch_size=64, shuffle=False)\n",
    "    test_dataset = utils.create_dataset(test_data, features, batch_size=64, shuffle=False) \n",
    "    \n",
    "    train_dataloader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=32, shuffle=False)\n",
    "    test_dataloader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)\n",
    "    \n",
    "\n",
    "    model = PerformerLM(\n",
    "        num_tokens = INPUT_SIZE,\n",
    "        max_seq_len = 321, # data.size()[1]\n",
    "        dim = INPUT_SIZE//2,\n",
    "        heads = 1, \n",
    "        depth = 32\n",
    "    )\n",
    "    \n",
    "    model = model_fit(model=model, EPOCHS=EPOCHS, loss_function=loss_function, train_loader=train_dataloader, val_loader=val_dataloader, n=INPUT_SIZE)\n",
    "    predictions, _, _, _, accuracy, roc_auc, pr_auc = test_model(model, test_loader, loss_function)\n",
    "    print(accuracy, roc_auc, pr_auc)\n",
    "\n",
    "#     current_time = datetime.datetime.now().strftime(\"%m%d%Y_%H:%M:%S\")\n",
    "#     experiment_name = \"Performer_\" + str(EPOCHS) + \"_\" + current_time\n",
    "\n",
    "#     logger = pl.loggers.TensorBoardLogger(save_dir='../logs/', name=experiment_name)\n",
    "\n",
    "#     checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "#         monitor='val_loss',\n",
    "#         dirpath=f'../logs/{experiment_name}',\n",
    "#         filename='{epoch:02d}-{val_loss:.3f}',\n",
    "#         mode='min')\n",
    "\n",
    "#     early_stop_callback = pl.callbacks.early_stopping.EarlyStopping(\n",
    "#         monitor=\"val_loss\", \n",
    "#         min_delta=0.00, \n",
    "#         patience=4, \n",
    "#         verbose=False, \n",
    "#         mode=\"min\"\n",
    "#     )\n",
    "\n",
    "#     trainer = pl.Trainer(\n",
    "#         max_epochs=EPOCHS, \n",
    "#         gpus=[1],  \n",
    "#         benchmark=True, \n",
    "#         check_val_every_n_epoch=1, \n",
    "#         logger=logger,\n",
    "#         callbacks=[checkpoint_callback, early_stop_callback])\n",
    "\n",
    "#     \"\"\"if i == 0:\n",
    "#         with profile(\n",
    "#             activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], profile_memory=True, record_shapes=True\n",
    "#         ) as prof:\n",
    "#         with torch.cuda.profiler.profile() as prof:\n",
    "#             with record_function(\"model_training\"):\n",
    "#                 trainer.fit(model)\n",
    "#         time_memory_consumption(prof.key_averages().table(), '../models/training_{}.txt'.format(experiment_name))\n",
    "#     else:\"\"\"\n",
    "#     trainer.fit(model)\n",
    "#     torch.save(model.model.state_dict(), '../models/{}.pth'.format(experiment_name))\n",
    "\n",
    "#     dict_logs = utils.plot_train_process(logger.log_dir)\n",
    "#     plt.show()\n",
    "\n",
    "#     \"\"\"if i == 0:\n",
    "#         with profile(\n",
    "#             activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], profile_memory=True, record_shapes=True\n",
    "#         ) as prof:\n",
    "#         with torch.cuda.profiler.profile() as prof:\n",
    "#             with record_function(\"model_testing\"):\n",
    "#                 test_predictions, test_targets, metric = utils.test_model(model, test_dataset)\n",
    "#         time_memory_consumption(prof.key_averages().table(), '../models/testing_{}.txt'.format(experiment_name))\n",
    "#     else:\"\"\"\n",
    "#     test_predictions, test_targets, metric = utils.test_model(model, test_dataset)\n",
    "\n",
    "#     metrics['Accuracy'].append(metric[0])\n",
    "#     metrics['ROC AUC'].append(metric[1])\n",
    "#     metrics['PR AUC'].append(metric[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric_name, metric_val in metrics.items():\n",
    "    print('{}: {} ± {}'.format(metric_name, np.array(metric_val).mean(), np.array(metric_val).std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 2048, 512)\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth, max_seq_len, dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.size() torch.Size([32, 321, 305])\n",
    "dim = 305 = INPUT_SIZE\n",
    "max_seq_len = 321 = data.size()[1]\n",
    "depth = 32 = batch_size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
